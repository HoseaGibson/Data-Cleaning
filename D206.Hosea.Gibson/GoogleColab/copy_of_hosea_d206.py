# -*- coding: utf-8 -*-
"""Copy of Hosea.d206.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tV1TjK5IBPHsL4upcuHLT88c_blRdaHq
"""

#imports for project
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
import numpy as np

#Load data into a data frame
#read in data from csv file churn_raw_data.csv
df = pd.read_csv('/content/churn_raw_data.csv')

#Get first 5 rows to look at the data set
df.head()

#Show the number of columns and row
df.shape

#Get the information on all the columns that will describe the datatypes
df.dtypes

#Show all of the columns
df.columns.values

#Check for missing or na values
df.isna().sum()

#Check statistics on the data
#Could use this information to fill in null and empty values
df.describe()

#Remove column which is 'Unnamed'
df.drop(['Unnamed: 0'], axis=1, inplace=True)
df.head()

#Need to fill in and rename Item 1 - 8 with proper names
df.rename(columns= {
    'item1': 'Timely response',
    'item2': 'Timely fixes',
    'item3': 'Timely replacements',
    'item4': 'Reliability',
    'item5': 'Options',
    'item6': 'Respectful response',
    'item7': 'Courteous exchange',
    'item8': 'Evidence of active listening',
}, inplace =True)
df.head(3)

#Fill in missing Value with some type of data

#Childeren column fill in with 0 because not really needing this column
#but just want to have some type of data passed in
df.Children.fillna('0', inplace=True)
#Techie will fill in with - because same is true column will not be used
df.Techie.fillna('-', inplace=True)
#Tech support will fill in with - because same is true column will not be used
df.TechSupport.fillna('-', inplace=True)
#Phone will fill in with - because same is true column will not be used
df.Phone.fillna('-', inplace=True)

#For Age, Income, Tenure, bandwith will fill in those with the mean value of each column
df.fillna(df.mean(), inplace=True)

#Check filled in na values
df.isna().sum()

#Making sure data was saved and filled in the proper values for missing data of first 15 rows
df.head(20)

#Check for duplicates 
df.duplicated()

#Check the count of how many people are churning
df['Churn'].value_counts()

#Visualize count of customer churn
sns.countplot(df['Churn'])

#Get the percentage of customers leaving
numberRetained = df[df.Churn == 'No'].shape[0] #Getting number of rows that didnt churn
numberChurned = df[df.Churn == 'Yes'].shape[0] #Getting number of rows that did churn

# Calculate and print customers that stayed
print(numberRetained / (numberRetained + numberChurned) * 100, '% of customers who did not churn!')

# Calculate and print customers that did not stay
print(numberChurned / (numberRetained + numberChurned) * 100, '% of customers who did churn!')

#Visualize the churn count for males and females
sns.countplot(x='Gender', hue='Churn', data = df)

#Since above didnt show to much about if gender was a effect on who churns or not look somewhere else
#Visualize internet column and count
sns.countplot(x='InternetService', hue='Churn', data =df)

#Shows the highest count who did not churn was fiber optics
#Shows that more with dsl churned a little more than fiber

#Create a box plot and see outlier
tenure = df.boxplot(['Tenure'])

monthly = df.boxplot(['MonthlyCharge'])

# Can see that there are some outliers in the monthly charges

#Visualize another column and count
tenureCharges = ['Tenure', 'MonthlyCharge']
#Create a histogram
fig, ax = plt.subplots(1,2, figsize=(28,8)) 
df[df.Churn == 'No'][tenureCharges].hist(bins=20, color = 'green', alpha=0.5, ax=ax)
df[df.Churn == 'Yes'][tenureCharges].hist(bins=20, color = 'red', alpha=0.5, ax=ax)

#Save a cleaned csv data set
df.to_csv('churn_cleaned_csv')

clean = pd.read_csv('churn_cleaned_csv')

clean.isna().sum() #Making sure set is cleaned and loaded properly

#Remove some columns and start from tenure
removedColumns = clean.loc[:, 'Tenure':'Evidence of active listening']
#Check results of the slice return 5 rows
removedColumns.head(5)

#Normalize and choose the which elements to extract
normalData = (removedColumns - removedColumns.mean())/removedColumns.std()

pca = PCA(n_components=removedColumns.shape[1])

#Get a list of names
names = removedColumns[['Tenure',	'MonthlyCharge',	'Bandwidth_GB_Year'
                      ,	'Timely response', 'Timely fixes',	'Timely replacements',	'Reliability'
                      ,	'Options',	'Respectful response',	'Courteous exchange',	'Evidence of active listening']]
pNames=[]
for i, col in enumerate(names.columns):
  pNames.append('PCA' + str(i+1))
print(pNames)

#Change to a set of Elements
pca.fit(normalData)
pcaData = pd.DataFrame(pca.transform(normalData), columns=pNames)

# Create a scree plot
plt.plot(pca.explained_variance_ratio_)
plt.xlabel('# Elements')
plt.ylabel('Variance')
plt.show();

matrixs = np.dot(normalData.T, normalData)/removedColumns.shape[0]
eigen = [np.dot(eigenvector.T, np.dot(matrixs,eigenvector)) for eigenvector in pca.components_]

# Create plot to show Eigenvalues
plt.plot(eigen)
plt.xlabel('# Components')
plt.ylabel('Eigenvalue')
plt.show();

# Need to get a small quantity of elements
for pc, var in zip(pNames, np.cumsum(pca.explained_variance_ratio_)*100): print(pc, var)

"""# New Section"""

rotate = pd.DataFrame(pca.components_.T, columns = pNames, index = names.columns)
print(rotate)

loads = pd.DataFrame(pca.components_.T, columns = pNames,index = removedColumns.columns) # Show output of the loadsf
loads

# Reducing data set to 4
reduced = pcaData.iloc[ : , 0:4]
print(reduced)